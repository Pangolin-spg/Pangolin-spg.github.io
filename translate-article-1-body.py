#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¿»è¯‘ç¬¬ä¸€ç¯‡æ–‡ç« çš„æ­£æ–‡æ®µè½
Getting Started with Amazon Scraping API
"""

import re

filename = 'zh/articles/getting-started-amazon-scraping-api.html'
print(f"ğŸ“ æ­£åœ¨ç¿»è¯‘æ­£æ–‡æ®µè½: {filename}")

with open(filename, 'r', encoding='utf-8') as f:
    content = f.read()

# å®šä¹‰è¦ç¿»è¯‘çš„æ®µè½æ˜ å°„ (åŸæ–‡ç‰¹å¾ç‰‡æ®µ -> å®Œæ•´ä¸­æ–‡ç¿»è¯‘)
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ re.sub æ¥è¿›è¡Œæ›¿æ¢ï¼Œå°½é‡åŒ¹é…å®Œæ•´çš„ p æ ‡ç­¾å†…å®¹
translations = [
    (
        r'In the competitive world of e-commerce, data is power\. Whether you\'re building a price monitoring tool, analyzing competitor strategies, or conducting market research, access to accurate and real-time Amazon product data is essential\.',
        'åœ¨ç«äº‰æ¿€çƒˆçš„ç”µå•†ä¸–ç•Œä¸­ï¼Œæ•°æ®å°±æ˜¯åŠ›é‡ã€‚æ— è®ºæ‚¨æ˜¯æ„å»ºä»·æ ¼ç›‘æ§å·¥å…·ã€åˆ†æç«äº‰å¯¹æ‰‹ç­–ç•¥ï¼Œè¿˜æ˜¯è¿›è¡Œå¸‚åœºç ”ç©¶ï¼Œè·å–å‡†ç¡®ä¸”å®æ—¶çš„ Amazon äº§å“æ•°æ®è‡³å…³é‡è¦ã€‚'
    ),
    (
        r'However, scraping Amazon data at scale comes with significant challenges: CAPTCHAs, IP bans, changing HTML structures, and complex anti-bot measures\. That\'s where <span class="text-accent-cyan font-semibold">Pangol Info\'s Amazon Scraping API</span> comes in\.',
        'ç„¶è€Œï¼Œå¤§è§„æ¨¡æŠ“å– Amazon æ•°æ®é¢ä¸´ç€å·¨å¤§æŒ‘æˆ˜ï¼šéªŒè¯ç ã€IP å°ç¦ã€ä¸æ–­å˜åŒ–çš„ HTML ç»“æ„ä»¥åŠå¤æ‚çš„åçˆ¬è™«æªæ–½ã€‚è¿™æ­£æ˜¯ <span class="text-accent-cyan font-semibold">Pangol Info Amazon æ•°æ®æŠ“å– API</span> å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚'
    ),
    (
        r'In this comprehensive guide, we\'ll walk you through everything you need to know to get started with our API, from obtaining your API key to making your first request and handling complex data extraction scenarios\.',
        'åœ¨è¿™ä»½ç»¼åˆæŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†å¸¦æ‚¨äº†è§£å¼€å§‹ä½¿ç”¨æˆ‘ä»¬éœ€è¦çŸ¥é“çš„ä¸€åˆ‡ï¼Œä»è·å– API å¯†é’¥åˆ°å‘é€ç¬¬ä¸€ä¸ªè¯·æ±‚ä»¥åŠå¤„ç†å¤æ‚çš„æ•°æ®æå–åœºæ™¯ã€‚'
    ),
    # Why Amazon Product Data Extraction Matters
    (
        r'Amazon is the world\'s largest e-commerce marketplace, making it a goldmine of data for businesses and developers\. Extracting this data allows you to:',
        'Amazon æ˜¯å…¨çƒæœ€å¤§çš„ç”µå•†å¸‚åœºï¼Œå¯¹äºä¼ä¸šå’Œå¼€å‘è€…æ¥è¯´æ˜¯ä¸€ä¸ªå·¨å¤§çš„æ•°æ®é‡‘çŸ¿ã€‚æå–è¿™äº›æ•°æ®å¯ä»¥å¸®åŠ©æ‚¨ï¼š'
    ),
    (
        r'Monitor price changes in real-time across millions of products',
        'å®æ—¶ç›‘æ§æ•°ç™¾ä¸‡ç§äº§å“çš„ä»·æ ¼å˜åŒ–'
    ),
    (
        r'Track competitor inventory levels and stock availability',
        'è·Ÿè¸ªç«äº‰å¯¹æ‰‹çš„åº“å­˜æ°´å¹³å’Œä¾›è´§æƒ…å†µ'
    ),
    (
        r'Analyze product reviews and sentiment to improve your own offerings',
        'åˆ†æäº§å“è¯„è®ºå’Œæƒ…æ„Ÿï¼Œä»¥æ”¹è¿›æ‚¨è‡ªå·±çš„äº§å“'
    ),
    (
        r'Discover trending products and profitable niches',
        'å‘ç°çƒ­é—¨äº§å“å’Œæœ‰åˆ©å¯å›¾çš„åˆ©åŸºå¸‚åœº'
    ),
    (
        r'Optimize your advertising campaigns based on competitor keywords',
        'æ ¹æ®ç«äº‰å¯¹æ‰‹çš„å…³é”®è¯ä¼˜åŒ–æ‚¨çš„å¹¿å‘Šæ´»åŠ¨'
    ),
    # Understanding Pangol Info's API
    (
        r'Our API handles all the heavy lifting of web scraping, including proxy rotation, CAPTCHA solving, and browser rendering\. You simply send a request to our endpoint, and we return structured JSON data containing all the product details you need\.',
        'æˆ‘ä»¬çš„ API å¤„ç†æ‰€æœ‰ç¹é‡çš„ç½‘é¡µæŠ“å–å·¥ä½œï¼ŒåŒ…æ‹¬ä»£ç†è½®æ¢ã€éªŒè¯ç è§£æå’Œæµè§ˆå™¨æ¸²æŸ“ã€‚æ‚¨åªéœ€å‘æˆ‘ä»¬çš„ç«¯ç‚¹å‘é€è¯·æ±‚ï¼Œæˆ‘ä»¬å°±ä¼šè¿”å›åŒ…å«æ‚¨æ‰€éœ€çš„æ‰€æœ‰äº§å“è¯¦æƒ…çš„ç»“æ„åŒ– JSON æ•°æ®ã€‚'
    ),
    (
        r'Key features include:',
        'ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š'
    ),
    (
        r'<strong>High Success Rate:</strong> 99\.9% success rate with automated retries',
        '<strong>é«˜æˆåŠŸç‡ï¼š</strong> 99.9% çš„æˆåŠŸç‡ï¼Œæ”¯æŒè‡ªåŠ¨é‡è¯•'
    ),
    (
        r'<strong>Real-Time Data:</strong> Get fresh data directly from Amazon live pages',
        '<strong>å®æ—¶æ•°æ®ï¼š</strong> ç›´æ¥ä» Amazon å®æ—¶é¡µé¢è·å–æœ€æ–°æ•°æ®'
    ),
    (
        r'<strong>Geo-Targeting:</strong> Scrape data from any Amazon marketplace region \(US, UK, DE, JP, etc\.\)',
        '<strong>åœ°ç†å®šä½ï¼š</strong> ä»ä»»ä½• Amazon å¸‚åœºåŒºåŸŸï¼ˆç¾å›½ã€è‹±å›½ã€å¾·å›½ã€æ—¥æœ¬ç­‰ï¼‰æŠ“å–æ•°æ®'
    ),
    (
        r'<strong>Scalable Infrastructure:</strong> Handle millions of requests per day without blocking',
        '<strong>å¯æ‰©å±•æ¶æ„ï¼š</strong> æ¯å¤©å¤„ç†æ•°ç™¾ä¸‡ä¸ªè¯·æ±‚è€Œä¸ä¼šè¢«é˜»æ­¢'
    ),
    # Getting Started: Prerequisites
    (
        r'Before we dive into the code, make sure you have the following:',
        'åœ¨æ·±å…¥ä»£ç ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å…·å¤‡ä»¥ä¸‹æ¡ä»¶ï¼š'
    ),
    (
        r'A <strong>Pangol Info account</strong> \(Sign up for free to get 1,000 credits\)',
        'ä¸€ä¸ª <strong>Pangol Info è´¦æˆ·</strong>ï¼ˆå…è´¹æ³¨å†Œå¯è·å¾— 1,000 ç§¯åˆ†ï¼‰'
    ),
    (
        r'Your unique <strong>API Key</strong> from the dashboard',
        'æ§åˆ¶å°ä¸­æ‚¨å”¯ä¸€çš„ <strong>API Key</strong>'
    ),
    (
        r'Python installed on your machine \(or any HTTP client like Postman or cURL\)',
        'æ‚¨çš„æœºå™¨ä¸Šå·²å®‰è£… Pythonï¼ˆæˆ–ä»»ä½• HTTP å®¢æˆ·ç«¯ï¼Œå¦‚ Postman æˆ– cURLï¼‰'
    ),
    # Authentication and API Basics
    (
        r'All requests to the Pangol Info API must be authenticated using your API token\. You can pass the token either as a query parameter or in the authorization header\.',
        'æ‰€æœ‰å¯¹ Pangol Info API çš„è¯·æ±‚éƒ½å¿…é¡»ä½¿ç”¨æ‚¨çš„ API ä»¤ç‰Œè¿›è¡Œèº«ä»½éªŒè¯ã€‚æ‚¨å¯ä»¥å°†ä»¤ç‰Œä½œä¸ºæŸ¥è¯¢å‚æ•°ä¼ é€’ï¼Œä¹Ÿå¯ä»¥åœ¨æˆæƒæ ‡å¤´ä¸­ä¼ é€’ã€‚'
    ),
    (
        r'The base endpoint for scraping is:',
        'æŠ“å–çš„åŸºç¡€ç«¯ç‚¹æ˜¯ï¼š'
    ),
    (
        r'For security reasons, we recommend setting your API token as an environment variable rather than hardcoding it in your scripts\.',
        'å‡ºäºå®‰å…¨åŸå› ï¼Œå»ºè®®å°†æ‚¨çš„ API ä»¤ç‰Œè®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œè€Œä¸æ˜¯å°†å…¶ç¡¬ç¼–ç åœ¨è„šæœ¬ä¸­ã€‚'
    ),
    # Extracting Product Data
    (
        r'Now let\'s look at how to extract various types of data from Amazon\.',
        'ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä» Amazon æå–å„ç§ç±»å‹çš„æ•°æ®ã€‚'
    ),
    (
        r'To scrape a product detail page, you need the product\'s ASIN \(Amazon Standard Identification Number\) or the full product URL\.',
        'è¦æŠ“å–äº§å“è¯¦æƒ…é¡µï¼Œæ‚¨éœ€è¦äº§å“çš„ ASINï¼ˆAmazon æ ‡å‡†è¯†åˆ«ç ï¼‰æˆ–å®Œæ•´çš„äº§å“ URLã€‚'
    ),
    (
        r'Here\'s a simple Python script to get product title, price, and rating:',
        'è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ Python è„šæœ¬ï¼Œç”¨äºè·å–äº§å“æ ‡é¢˜ã€ä»·æ ¼å’Œè¯„åˆ†ï¼š'
    ),
    # Understanding Response
    (
        r'The API returns a JSON object with a <code[^>]*>scraped_content</code> field containing the parsed data\. Here\'s what the structure looks like:',
        'API è¿”å›ä¸€ä¸ªåŒ…å« <code class="text-accent-cyan">scraped_content</code> å­—æ®µçš„ JSON å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«è§£æåçš„æ•°æ®ã€‚ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š'
    ),
    # Price Monitoring
    (
        r'One of the most common use cases is tracking price history\. You can set up a scheduled job \(cron job\) to run this script periodically and save the data to a database\.',
        'æœ€å¸¸è§çš„ç”¨ä¾‹ä¹‹ä¸€æ˜¯è·Ÿè¸ªä»·æ ¼å†å²ã€‚æ‚¨å¯ä»¥è®¾ç½®å®šæ—¶ä»»åŠ¡ï¼ˆcron jobï¼‰å®šæœŸè¿è¡Œæ­¤è„šæœ¬å¹¶å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ã€‚'
    ),
    # Best Practices
    (
        r'To ensure optimal performance and minimize errors, follow these best practices:',
        'ä¸ºç¡®ä¿æœ€ä½³æ€§èƒ½å¹¶æœ€å¤§é™åº¦åœ°å‡å°‘é”™è¯¯ï¼Œè¯·éµå¾ªä»¥ä¸‹æœ€ä½³å®è·µï¼š'
    ),
    (
        r'<strong>Respect Rate Limits:</strong> While our API handles rotation, sending too many concurrent requests might trigger account-level limits\. Start with 5-10 concurrent threads\.',
        '<strong>éµå®ˆé€Ÿç‡é™åˆ¶ï¼š</strong> è™½ç„¶æˆ‘ä»¬çš„ API å¤„ç†è½®æ¢ï¼Œä½†å‘é€è¿‡å¤šå¹¶å‘è¯·æ±‚å¯èƒ½ä¼šè§¦å‘è´¦æˆ·çº§é™åˆ¶ã€‚å»ºè®®ä» 5-10 ä¸ªå¹¶å‘çº¿ç¨‹å¼€å§‹ã€‚'
    ),
    (
        r'<strong>Error Handling:</strong> Always wrap your API calls in try-except blocks to handle network timeouts or parsing errors gracefully\.',
        '<strong>é”™è¯¯å¤„ç†ï¼š</strong> å§‹ç»ˆå°† API è°ƒç”¨åŒ…è£…åœ¨ try-except å—ä¸­ï¼Œä»¥ä¼˜é›…åœ°å¤„ç†ç½‘ç»œè¶…æ—¶æˆ–è§£æé”™è¯¯ã€‚'
    ),
    (
        r'<strong>Use Webhooks:</strong> For large-scale scraping, use our async webhooks processing to receive results without keeping connections open\.',
        '<strong>ä½¿ç”¨ Webhooksï¼š</strong> å¯¹äºå¤§è§„æ¨¡æŠ“å–ï¼Œè¯·ä½¿ç”¨æˆ‘ä»¬çš„å¼‚æ­¥ Webhooks å¤„ç†æ¥æ¥æ”¶ç»“æœï¼Œè€Œæ— éœ€ä¿æŒè¿æ¥æ‰“å¼€ã€‚'
    ),
    # Conclusion
    (
        r'Getting started with Amazon data extraction doesn\'t have to be complicated\. with Pangol Info\'s API, you can focus on analyzing the data rather than fighting anti-bot measures\.',
        'å¼€å§‹ Amazon æ•°æ®æå–å¹¶ä¸ä¸€å®šå¾ˆå¤æ‚ã€‚ä½¿ç”¨ Pangol Info çš„ APIï¼Œæ‚¨å¯ä»¥ä¸“æ³¨äºåˆ†ææ•°æ®ï¼Œè€Œä¸æ˜¯ä¸åçˆ¬è™«æªæ–½ä½œæ–—äº‰ã€‚'
    ),
]

for pattern, replacement in translations:
    # å°è¯•ç›´æ¥æ›¿æ¢æ–‡æœ¬å†…å®¹
    # ä½¿ç”¨ re.sub è¿›è¡Œæ›¿æ¢ï¼Œå¿½ç•¥å¤§å°å†™ä»¥é˜²ä¸‡ä¸€
    # æˆ‘ä»¬åŒ¹é…åŸå§‹æ–‡æœ¬ï¼Œä¸åšå¤æ‚çš„æ­£åˆ™ï¼Œé™¤éå¿…è¦
    
    # ç®€å•çš„æ–‡æœ¬æ›¿æ¢
    if '\\' not in pattern:
        content = content.replace(pattern.replace('\\', ''), replacement)
    else:
        # æ­£åˆ™æ›¿æ¢
        content = re.sub(pattern, replacement, content)

print("âœ… ç¿»è¯‘å®Œæˆ")

with open(filename, 'w', encoding='utf-8') as f:
    f.write(content)
