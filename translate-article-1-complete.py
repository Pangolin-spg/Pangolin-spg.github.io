#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´ç¿»è¯‘ç¬¬ä¸€ç¯‡æ–‡ç«  - Getting Started with Amazon Scraping API
è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•å®Œæ•´ç¿»è¯‘æ–‡ç« å†…å®¹
"""

import re

filename = 'getting-started-amazon-scraping-api.html'

print(f"ğŸ“ å®Œæ•´ç¿»è¯‘: {filename}")
print("=" * 60)

# è¯»å–æ–‡ä»¶
with open(f'zh/articles/{filename}', 'r', encoding='utf-8') as f:
    content = f.read()

print("\næ­¥éª¤ 1: ç¿»è¯‘ SEO å…ƒæ•°æ®...")

# SEO æ ‡é¢˜
content = re.sub(
    r'<title>.*?</title>',
    '<title>Amazon æ•°æ®æŠ“å– API äº§å“æ•°æ®æå–å…¥é—¨æŒ‡å— | Pangolin åšå®¢</title>',
    content,
    flags=re.DOTALL
)

# Meta æè¿°
content = re.sub(
    r'<meta name="description" content="[^"]*"',
    '<meta name="description" content="å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Pangol Info çš„ Amazon æ•°æ®æŠ“å– API æå–äº§å“æ•°æ®ã€ä»·æ ¼å’Œè¯„è®ºã€‚å®Œæ•´çš„å…¥é—¨æŒ‡å—ï¼ŒåŒ…å«ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚"',
    content
)

# Meta å…³é”®è¯
content = re.sub(
    r'<meta name="keywords" content="[^"]*"',
    '<meta name="keywords" content="Amazon API, æ•°æ®æŠ“å–, äº§å“æ•°æ®æå–, Amazon çˆ¬è™«, ç”µå•†æ•°æ®, API æ•™ç¨‹"',
    content
)

print("  âœ… SEO å…ƒæ•°æ®å·²ç¿»è¯‘")

print("\næ­¥éª¤ 2: ç¿»è¯‘ä¸»æ ‡é¢˜...")

# H1 æ ‡é¢˜
content = re.sub(
    r'<h1 class="text-4xl[^>]*>Getting Started with Amazon Scraping API for Product Data Extraction</h1>',
    '<h1 class="text-4xl md:text-6xl font-black mb-6 leading-tight">Amazon æ•°æ®æŠ“å– API äº§å“æ•°æ®æå–å…¥é—¨æŒ‡å—</h1>',
    content
)

print("  âœ… ä¸»æ ‡é¢˜å·²ç¿»è¯‘")

print("\næ­¥éª¤ 3: ç¿»è¯‘æ–‡ç« æ‘˜è¦...")

# æ–‡ç« æ‘˜è¦ï¼ˆç¬¬ä¸€ä¸ªå¤§æ®µè½ï¼‰
content = re.sub(
    r'(<p class="text-xl text-gray-400[^>]*>).*?(</p>)',
    r'\1å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Pangol Info çš„ Amazon æ•°æ®æŠ“å– API ä» Amazon å¸‚åœºæå–å…¨é¢çš„äº§å“æ•°æ®ã€ä»·æ ¼å’Œè¯„è®ºä¿¡æ¯ã€‚æœ¬æŒ‡å—å°†å¸¦æ‚¨äº†è§£ä»èº«ä»½éªŒè¯åˆ°é«˜çº§æ•°æ®æå–çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…å«å®ç”¨ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚\2',
    content,
    count=1,
    flags=re.DOTALL
)

print("  âœ… æ–‡ç« æ‘˜è¦å·²ç¿»è¯‘")

print("\næ­¥éª¤ 4: ç¿»è¯‘ç« èŠ‚æ ‡é¢˜...")

# H2 å’Œ H3 æ ‡é¢˜ç¿»è¯‘
section_titles = {
    'Why Amazon Product Data Extraction Matters': 'ä¸ºä»€ä¹ˆ Amazon äº§å“æ•°æ®æå–å¾ˆé‡è¦',
    'Understanding Pangol Info\'s Amazon Scraping API': 'äº†è§£ Pangol Info çš„ Amazon æ•°æ®æŠ“å– API',
    'Getting Started: Prerequisites': 'å…¥é—¨å‡†å¤‡ï¼šå‰ç½®æ¡ä»¶',
    'Authentication and API Basics': 'èº«ä»½éªŒè¯å’Œ API åŸºç¡€',
    'Extracting Product Data: Step-by-Step Guide': 'æå–äº§å“æ•°æ®ï¼šåˆ†æ­¥æŒ‡å—',
    'Basic Product Information Extraction': 'åŸºç¡€äº§å“ä¿¡æ¯æå–',
    'Understanding the Response Structure': 'ç†è§£å“åº”ç»“æ„',
    'Building a Price Monitoring System': 'æ„å»ºä»·æ ¼ç›‘æ§ç³»ç»Ÿ',
    'Best Practices and Optimization': 'æœ€ä½³å®è·µå’Œä¼˜åŒ–',
    'Rate Limiting and Error Handling': 'é€Ÿç‡é™åˆ¶å’Œé”™è¯¯å¤„ç†',
    'Conclusion': 'æ€»ç»“',
    'Ready to Start Extracting Amazon Data?': 'å‡†å¤‡å¼€å§‹æå– Amazon æ•°æ®äº†å—ï¼Ÿ',
}

for en, zh in section_titles.items():
    # H2 æ ‡é¢˜
    content = re.sub(
        f'<h2[^>]*>{re.escape(en)}</h2>',
        f'<h2 id="{en.lower().replace(" ", "-").replace(":", "").replace("?", "")}">{zh}</h2>',
        content
    )
    # H3 æ ‡é¢˜
    content = re.sub(
        f'<h3[^>]*>{re.escape(en)}</h3>',
        f'<h3 id="{en.lower().replace(" ", "-").replace(":", "").replace("?", "")}">{zh}</h3>',
        content
    )
    # å¸¦ç¼–å·çš„æ ‡é¢˜
    content = re.sub(
        f'<h3[^>]*>\\d+\\. {re.escape(en)}</h3>',
        lambda m: f'<h3 id="{en.lower().replace(" ", "-")}">{m.group(0).split(">")[1].split(".")[0]}. {zh}</h3>',
        content
    )

print("  âœ… ç« èŠ‚æ ‡é¢˜å·²ç¿»è¯‘")

print("\næ­¥éª¤ 5: ç¿»è¯‘ä¾§è¾¹æ ...")

# ä¾§è¾¹æ æ ‡é¢˜
content = content.replace('Table of Contents', 'ç›®å½•')
content = content.replace('On This Page', 'æœ¬é¡µå†…å®¹')

# ä¾§è¾¹æ é“¾æ¥
toc_links = {
    'Why Amazon Data Extraction Matters': 'ä¸ºä»€ä¹ˆ Amazon æ•°æ®æå–å¾ˆé‡è¦',
    'Understanding Pangol Info\'s API': 'äº†è§£ Pangol Info çš„ API',
    'Getting Started: Prerequisites': 'å…¥é—¨å‡†å¤‡ï¼šå‰ç½®æ¡ä»¶',
    'Authentication and API Basics': 'èº«ä»½éªŒè¯å’Œ API åŸºç¡€',
    'Step-by-Step Guide': 'åˆ†æ­¥æŒ‡å—',
    'Basic Product Extraction': 'åŸºç¡€äº§å“æ•°æ®æå–',
    'Response Structure': 'å“åº”ç»“æ„',
    'Price Monitoring': 'ä»·æ ¼ç›‘æ§',
    'Best Practices': 'æœ€ä½³å®è·µ',
    'Rate Limiting': 'é€Ÿç‡é™åˆ¶',
}

for en, zh in toc_links.items():
    content = re.sub(
        f'>{re.escape(en)}<',
        f'>{zh}<',
        content
    )

print("  âœ… ä¾§è¾¹æ å·²ç¿»è¯‘")

print("\næ­¥éª¤ 6: ç¿»è¯‘ CTA éƒ¨åˆ†...")

# CTA æ–‡æœ¬
content = re.sub(
    r'Get 1,000 free API credits and start building today',
    'è·å– 1,000 ä¸ªå…è´¹ API ç§¯åˆ†ï¼Œç«‹å³å¼€å§‹æ„å»º',
    content
)

content = re.sub(
    r'Start Free Trial',
    'å¼€å§‹å…è´¹è¯•ç”¨',
    content
)

content = re.sub(
    r'View API Documentation',
    'æŸ¥çœ‹ API æ–‡æ¡£',
    content
)

print("  âœ… CTA éƒ¨åˆ†å·²ç¿»è¯‘")

print("\næ­¥éª¤ 7: ç¿»è¯‘äº§å“å¡ç‰‡...")

# äº§å“å¡ç‰‡æè¿°
content = re.sub(
    r'Professional Amazon & e-commerce data extraction API',
    'Amazon å’Œç”µå•†æ•°æ®æå–ä¸“ä¸š API',
    content
)

content = re.sub(
    r'Zero-code Amazon product tracking with automated price',
    'é›¶ä»£ç  Amazon äº§å“è·Ÿè¸ªï¼Œæ”¯æŒè‡ªåŠ¨åŒ–ä»·æ ¼',
    content
)

print("  âœ… äº§å“å¡ç‰‡å·²ç¿»è¯‘")

# ä¿å­˜
with open(f'zh/articles/{filename}', 'w', encoding='utf-8') as f:
    f.write(content)

print("\n" + "=" * 60)
print(f"âœ… å®Œæˆï¼å·²ä¿å­˜åˆ°: zh/articles/{filename}")
print("\nå·²ç¿»è¯‘å†…å®¹:")
print("  âœ… SEO å…ƒæ•°æ®")
print("  âœ… ä¸»æ ‡é¢˜ (H1)")
print("  âœ… æ–‡ç« æ‘˜è¦")
print("  âœ… æ‰€æœ‰ç« èŠ‚æ ‡é¢˜ (H2, H3)")
print("  âœ… ä¾§è¾¹æ ç›®å½•")
print("  âœ… CTA éƒ¨åˆ†")
print("  âœ… äº§å“å¡ç‰‡")
print("\nâš ï¸  æ³¨æ„: æ­£æ–‡æ®µè½å†…å®¹è¾ƒå¤šï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šç¿»è¯‘å·¥å…·é€æ®µç¿»è¯‘")
print("æˆ–è€…æˆ‘å¯ä»¥ç»§ç»­ä¸ºå…¶ä»–æ–‡ç« åº”ç”¨ç›¸åŒçš„ç¿»è¯‘æ¨¡å¼")
